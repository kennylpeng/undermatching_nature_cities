{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe1f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotting import create_bar_chart, create_stacked_bar_chart, plot_portfolio_outcome\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from create_student_df import create_student_df\n",
    "from create_program_df import create_program_df, add_selectivity_info, add_offer_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb46e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../clean_dfs/students_extended_export.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c6ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['offer_rate_match'] = df['offer_rate_match'].apply(lambda x: x if pd.notnull(x) else 1)\n",
    "df['offer_rates'] = df.apply(lambda row: [row[f'offer_rate_{i}'] for i in range(1, 13) if pd.notnull(row[f'offer_rate_{i}'])], axis=1)\n",
    "\n",
    "for metric in ['program_college_rate', 'program_grad_rate', 'impact', 'performance', 'aggregated_quality']:\n",
    "    df[f'{metric}_match'] = df.apply(lambda row: row[f'{metric}_match'] if pd.notnull(row[f'{metric}_match']) else row[f'{metric}_mp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ca484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder to save plots to\n",
    "savefolder = '../export_nature_cities_revisions'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f7e27",
   "metadata": {},
   "source": [
    "# Undermatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb40b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['undermatching'] = df['offer_rate_match'] - df['offer_rate_best_cf_pareto']\n",
    "df['undermatching_withinportfolio'] = df['offer_rate_match'] - df['offer_rate_best_cf_pareto_withinportfolio']\n",
    "\n",
    "for metric in ['offer_rate', 'program_college_rate', 'program_grad_rate', 'impact', 'performance', 'aggregated_quality']:\n",
    "    df[f'undermatching_{metric}'] = df[f'{metric}_best_cf_pareto'] - df[f'{metric}_match'] # opposite direction as offer rate\n",
    "    df[f'undermatching_withinportfolio_{metric}'] = df[f'{metric}_best_cf_pareto_withinportfolio'] - df[f'{metric}_match'] # opposite direction as offer rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b17865-2aa7-4084-a03c-36d408a0340b",
   "metadata": {},
   "source": [
    "## Summary table for undermatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d05dd9-1202-4f1d-ad2f-093d54ca7a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = ''\n",
    "for metric in ['offer_rate', 'program_college_rate', 'program_grad_rate', 'impact', 'performance']:\n",
    "    table_row = ''\n",
    "    table_row += str(round(df[f'{metric}_match'].mean(), 2)) + ' & '\n",
    "    for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "        table_row += str(round(df[df['ethnicity']==ethnicity][f'{metric}_match'].mean(), 2)) + ' & '\n",
    "    table_row += str(round(df[f'{metric}_best_cf_pareto'].mean(), 2)) + ' & '\n",
    "    for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "        table_row += str(round(df[df['ethnicity']==ethnicity][f'{metric}_best_cf_pareto'].mean(), 2)) + ' & '\n",
    "    table_row += str(round(df[f'undermatching_{metric}'].mean(), 2)) + ' & '\n",
    "    for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "        table_row += str(round(df[df['ethnicity']==ethnicity][f'undermatching_{metric}'].mean(), 2)) + ' & '\n",
    "    table += table_row + '\\n'\n",
    "\n",
    "    table_row = ''\n",
    "    table_row += str(round(df[df['poverty']==True][f'{metric}_match'].mean(), 2)) + ' & '\n",
    "    for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "        table_row += str(round(df[(df['ethnicity']==ethnicity) & (df['poverty']==True)][f'{metric}_match'].mean(), 2)) + ' & '\n",
    "    table_row += str(round(df[df['poverty']==True][f'{metric}_best_cf_pareto'].mean(), 2)) + ' & '\n",
    "    for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "        table_row += str(round(df[(df['ethnicity']==ethnicity) & (df['poverty']==True)][f'{metric}_best_cf_pareto'].mean(), 2)) + ' & '\n",
    "    table_row += str(round(df[df['poverty']==True][f'undermatching_{metric}'].mean(), 2)) + ' & '\n",
    "    for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "        table_row += str(round(df[(df['ethnicity']==ethnicity) & (df['poverty']==True)][f'undermatching_{metric}'].mean(), 2)) + ' & '\n",
    "    table += table_row + '\\n'\n",
    "\n",
    "    table_row = ''\n",
    "    table_row += str(round(df[df['poverty']==False][f'{metric}_match'].mean(), 2)) + ' & '\n",
    "    for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "        table_row += str(round(df[(df['ethnicity']==ethnicity) & (df['poverty']==False)][f'{metric}_match'].mean(), 2)) + ' & '\n",
    "    table_row += str(round(df[df['poverty']==False][f'{metric}_best_cf_pareto'].mean(), 2)) + ' & '\n",
    "    for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "        table_row += str(round(df[(df['ethnicity']==ethnicity) & (df['poverty']==False)][f'{metric}_best_cf_pareto'].mean(), 2)) + ' & '\n",
    "    table_row += str(round(df[df['poverty']==False][f'undermatching_{metric}'].mean(), 2)) + ' & '\n",
    "    for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "        table_row += str(round(df[(df['ethnicity']==ethnicity) & (df['poverty']==False)][f'undermatching_{metric}'].mean(), 2)) + ' & '\n",
    "    table += table_row + '\\n'\n",
    "\n",
    "with open(f'{savefolder}/undermatching_table.txt', 'w') as f:\n",
    "    f.write(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9eefc0",
   "metadata": {},
   "source": [
    "## Offer Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854dc489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_bar_chart(df, 'offer_rate_match', title='Offer Rate of Match', save=False, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ce47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, title in [('program_grad_rate', 'Graduation Rate'), ('program_college_rate', 'College Attendance Rate'), ('impact', 'Impact'), ('performance', 'Performance'), ('aggregated_quality', 'Aggregated Quality')]:\n",
    "    create_bar_chart(df, f'{metric}_match', title=title, save=True, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258118bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_stacked_bar_chart(df, ['offer_rate_match', 'offer_rate_best_cf_pareto_withinportfolio', 'offer_rate_best_cf_pareto'], labels=['Match', 'CF (In Portfolio)', 'CF'], title='Offer Rate', save=False, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, title in [('program_grad_rate', 'Graduation Rate'), ('program_college_rate', 'College Attendance Rate'), ('impact', 'Impact'), ('performance', 'Performance'), ('aggregated_quality', 'Aggregated Quality')]:\n",
    "    create_stacked_bar_chart(df, [f'{metric}_best_cf_pareto', f'{metric}_best_cf_pareto_withinportfolio', f'{metric}_match'], labels=['CF', 'CF (In Portfolio)', 'Match'], title=title, save=True, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b1d3d",
   "metadata": {},
   "source": [
    "# Undermatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0011a905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_bar_chart(df, 'undermatching', title='Undermatching', save=False, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965cde92",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stacked_bar_chart(df, ['undermatching', 'undermatching_withinportfolio'], labels=['Overall', 'In Portfolio'], title='Undermatching', save=False, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395e38e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for metric, title in [('program_grad_rate', 'Graduation Rate'), ('program_college_rate', 'College Attendance Rate'), ('impact', 'Impact'), ('performance', 'Performance'), ('aggregated_quality', 'Aggregated Quality')]:\n",
    "    create_stacked_bar_chart(df, [f'undermatching_{metric}', f'undermatching_withinportfolio_{metric}'], labels=['Overall', 'In Portfolio'], title=f'Undermatching ({title})', save=True, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd0d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, title in [('program_grad_rate', 'Graduation Rate'), ('program_college_rate', 'College Attendance Rate'), ('impact', 'Impact'), ('performance', 'Performance'), ('aggregated_quality', 'Aggregated Quality')]:\n",
    "    create_bar_chart(df, f'undermatching_{metric}', title=f'Undermatching ({title})', save=True, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083426a2",
   "metadata": {},
   "source": [
    "### Undermatching by student competitiveness (i.e., best cf offer rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f542661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bin(offer_rate, bins):\n",
    "    for i in range(len(bins)-1):\n",
    "        if offer_rate >= bins[i] and offer_rate < bins[i+1]:\n",
    "            return i\n",
    "    \n",
    "    return len(bins)-2\n",
    "\n",
    "bins = [0, 0.2, 0.4, 0.6, 0.8, 1, 100]\n",
    "df['offer_rate_cf_bin'] = df['offer_rate_best_cf_pareto'].apply(lambda x: get_bin(x, bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6e0f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names_pretty = {\n",
    "        'asian': 'Asian', 'black':'Black', 'hispanic':'Hispanic', 'white':'white',\n",
    "        'M':'Male',\n",
    "        'F' : 'Female'\n",
    "    }\n",
    "\n",
    "groups = ['asian', 'black', 'hispanic', 'white']\n",
    "undermatching_values = {}\n",
    "for group in groups:\n",
    "    sns.lineplot(x='offer_rate_cf_bin', y='undermatching', data=df[df['ethnicity']==group], label=group_names_pretty[group])\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "plt.xticks(range(len(bins)-1), ['[0, 0.2)', '[0.2, 0.4)', '[0.4, 0.6)', '[0.6, 0.8)', '[0.8, 1)', '1'])\n",
    "plt.xlabel('Offer Rate of Most Selective Counterfactual', fontsize=12)\n",
    "plt.ylabel('Undermatching', fontsize=12)\n",
    "sns.despine()\n",
    "plt.savefig(f'{savefolder}/offer_rate_by_best_cf.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e5c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, title in [('program_grad_rate', 'Graduation Rate'), ('program_college_rate', 'College Attendance Rate'), ('impact', 'Impact'), ('performance', 'Performance'), ('aggregated_quality', 'Aggregated Quality')]:\n",
    "\n",
    "    group_names_pretty = {\n",
    "            'asian': 'Asian', 'black':'Black', 'hispanic':'Hispanic', 'white':'white',\n",
    "            'M':'Male',\n",
    "            'F' : 'Female'\n",
    "        }\n",
    "\n",
    "    groups = ['asian', 'black', 'hispanic', 'white']\n",
    "    undermatching_values = {}\n",
    "    for group in groups:\n",
    "        sns.lineplot(x=f'offer_rate_cf_bin', y=f'undermatching_{metric}', data=df[df['ethnicity']==group], label=group_names_pretty[group])\n",
    "\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xticks(range(len(bins)-1), ['[0, 0.2)', '[0.2, 0.4)', '[0.4, 0.6)', '[0.6, 0.8)', '[0.8, 1)', '1'])\n",
    "    plt.xlabel(f'Offer Rate of Most Selective Counterfactual', fontsize=12)\n",
    "    plt.ylabel(f'Undermatching ({title})', fontsize=12)\n",
    "    sns.despine()\n",
    "    plt.savefig(f'{savefolder}/{title}_by_best_cf.png', dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8909d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tier'] = df['avg_grades_for_tier'].apply(\n",
    "        lambda x: 1 if x >= 350 else (2 if x >= 250 else (3 if x >= 150 else 4))\n",
    "    )\n",
    "\n",
    "undermatching_values = {}\n",
    "for group in groups:\n",
    "    sns.lineplot(x='tier', y='undermatching', data=df[df['ethnicity']==group], label=group_names_pretty[group])\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "plt.xticks([1, 2, 3, 4], ['1 (Top)', '2', '3', '4 (Bottom)'])\n",
    "plt.xlabel('Tier', fontsize=12)\n",
    "plt.ylabel('Undermatching', fontsize=12)\n",
    "sns.despine()\n",
    "plt.savefig(f'{savefolder}/offer_rate_by_tier.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, title in [('program_grad_rate', 'Graduation Rate'), ('program_college_rate', 'College Attendance Rate'), ('impact', 'Impact'), ('performance', 'Performance'), ('aggregated_quality', 'Aggregated Quality')]:\n",
    "\n",
    "    df['tier'] = df['avg_grades_for_tier'].apply(\n",
    "            lambda x: 1 if x >= 350 else (2 if x >= 250 else (3 if x >= 150 else 4))\n",
    "        )\n",
    "\n",
    "    undermatching_values = {}\n",
    "    for group in groups:\n",
    "        sns.lineplot(x='tier', y=f'undermatching_{metric}', data=df[df['ethnicity']==group], label=group_names_pretty[group])\n",
    "\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xticks([1, 2, 3, 4], ['1 (Top)', '2', '3', '4 (Bottom)'])\n",
    "    plt.xlabel('Tier', fontsize=12)\n",
    "    plt.ylabel(f'Undermatching ({title})', fontsize=12)\n",
    "    sns.despine()\n",
    "    plt.savefig(f'{savefolder}/{title}_by_tier.png', dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61294d92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_tiebreaker_num(tiebreaker):\n",
    "    if type(tiebreaker)==str:\n",
    "        head = tiebreaker[:5]\n",
    "        return int(format(int(head, 16), 'd'))/1048518\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "bins_tiebreaker = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "df['tiebreaker_num'] = df['tiebreaker'].apply(lambda x: get_tiebreaker_num(x))\n",
    "df['tiebreaker_bin'] = df['tiebreaker_num'].apply(lambda x: get_bin(x, bins_tiebreaker))\n",
    "\n",
    "undermatching_values = {}\n",
    "for group in groups:\n",
    "    sns.lineplot(x='tiebreaker_bin', y=f'undermatching', data=df[df['ethnicity']==group], label=group_names_pretty[group])\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "plt.xticks(range(len(bins_tiebreaker)-1), ['[0, 0.2)', '[0.2, 0.4)', '[0.4, 0.6)', '[0.6, 0.8)', '[0.8, 1)'])\n",
    "plt.xlabel('Lottery Number', fontsize=12)\n",
    "plt.ylabel(f'Undermatching', fontsize=12)\n",
    "sns.despine()\n",
    "plt.savefig(f'{savefolder}/offer_rate_by_lottery.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b11a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for metric, title in [('program_grad_rate', 'Graduation Rate'), ('program_college_rate', 'College Attendance Rate'), ('impact', 'Impact'), ('performance', 'Performance'), ('aggregated_quality', 'Aggregated Quality')]:\n",
    "\n",
    "    undermatching_values = {}\n",
    "    for group in groups:\n",
    "        sns.lineplot(x='tiebreaker_bin', y=f'undermatching_{metric}', data=df[df['ethnicity']==group], label=group_names_pretty[group])\n",
    "\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xticks(range(len(bins_tiebreaker)-1), ['[0, 0.2)', '[0.2, 0.4)', '[0.4, 0.6)', '[0.6, 0.8)', '[0.8, 1)'])\n",
    "    plt.xlabel('Lottery Number', fontsize=12)\n",
    "    plt.ylabel(f'Undermatching ({title})', fontsize=12)\n",
    "    sns.despine()\n",
    "    plt.savefig(f'{savefolder}/{title}_by_lottery.png', dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d9f19e",
   "metadata": {},
   "source": [
    "## Lottery number analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in groups:\n",
    "    sns.lineplot(x='tiebreaker_bin', y=f'offer_rate_1', data=df[df['ethnicity']==group], label=group_names_pretty[group])\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "plt.xticks(range(len(bins_tiebreaker)-1), ['[0, 0.2)', '[0.2, 0.4)', '[0.4, 0.6)', '[0.6, 0.8)', '[0.8, 1)'])\n",
    "plt.xlabel('Lottery Number', fontsize=12)\n",
    "plt.ylabel(f'Offer Rate of Top Choice', fontsize=12)\n",
    "sns.despine()\n",
    "plt.savefig(f'{savefolder}/offer_rate_1_by_lottery.png', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for group in groups:\n",
    "    sns.lineplot(x='tiebreaker_bin', y=f'ofchoices', data=df[df['ethnicity']==group], label=group_names_pretty[group])\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "plt.xticks(range(len(bins_tiebreaker)-1), ['[0, 0.2)', '[0.2, 0.4)', '[0.4, 0.6)', '[0.6, 0.8)', '[0.8, 1)'])\n",
    "plt.xlabel('Lottery Number', fontsize=12)\n",
    "plt.ylabel(f'List Length', fontsize=12)\n",
    "sns.despine()\n",
    "plt.savefig(f'{savefolder}/ofchoices_by_lottery.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d6a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['offer_rates_mean'] = df['offer_rates'].apply(lambda x: np.mean(x))\n",
    "df['offer_rates_max'] = df['offer_rates'].apply(lambda x: np.max(x))\n",
    "\n",
    "for group in groups:\n",
    "    sns.lineplot(x='tiebreaker_bin', y=f'offer_rates_mean', data=df[df['ethnicity']==group], label=group_names_pretty[group])\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "plt.xticks(range(len(bins_tiebreaker)-1), ['[0, 0.2)', '[0.2, 0.4)', '[0.4, 0.6)', '[0.6, 0.8)', '[0.8, 1)'])\n",
    "plt.xlabel('Lottery Number', fontsize=12)\n",
    "plt.ylabel(f'Mean Offer Rate', fontsize=12)\n",
    "sns.despine()\n",
    "plt.savefig(f'{savefolder}/offer_rates_mean_by_lottery.png', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "for group in groups:\n",
    "    sns.lineplot(x='tiebreaker_bin', y=f'offer_rates_max', data=df[df['ethnicity']==group], label=group_names_pretty[group])\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "plt.xticks(range(len(bins_tiebreaker)-1), ['[0, 0.2)', '[0.2, 0.4)', '[0.4, 0.6)', '[0.6, 0.8)', '[0.8, 1)'])\n",
    "plt.xlabel('Lottery Number', fontsize=12)\n",
    "plt.ylabel(f'Max Offer Rate', fontsize=12)\n",
    "sns.despine()\n",
    "plt.savefig(f'{savefolder}/offer_rates_max_by_lottery.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b3274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "formula = \"offer_rate_1 ~ ethnicity + tiebreaker_num + tiebreaker_num:ethnicity\"\n",
    "mod = smf.ols(formula = formula, data = df)\n",
    "res = mod.fit()\n",
    "with open(f'regressions-20250809/lottery_offer_rate_1.txt', 'w') as f:\n",
    "        f.write(res.summary().as_latex())\n",
    "display(res.summary())\n",
    "\n",
    "formula = \"ofchoices ~ ethnicity + tiebreaker_num + tiebreaker_num:ethnicity\"\n",
    "mod = smf.ols(formula = formula, data = df)\n",
    "res = mod.fit()\n",
    "with open(f'regressions-20250809/lottery_ofchoices.txt', 'w') as f:\n",
    "        f.write(res.summary().as_latex())\n",
    "display(res.summary())\n",
    "\n",
    "formula = \"offer_rates_mean ~ ethnicity + tiebreaker_num + tiebreaker_num:ethnicity\"\n",
    "mod = smf.ols(formula = formula, data = df)\n",
    "res = mod.fit()\n",
    "with open(f'regressions-20250809/lottery_offer_rate_mean.txt', 'w') as f:\n",
    "        f.write(res.summary().as_latex())\n",
    "display(res.summary())\n",
    "\n",
    "formula = \"offer_rates_max ~ ethnicity + tiebreaker_num + tiebreaker_num:ethnicity\"\n",
    "mod = smf.ols(formula = formula, data = df)\n",
    "res = mod.fit()\n",
    "with open(f'regressions-20250809/lottery_offer_rate_max.txt', 'w') as f:\n",
    "        f.write(res.summary().as_latex())\n",
    "res = mod.fit()\n",
    "display(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170d8f2a",
   "metadata": {},
   "source": [
    "# Interpretable Portfolio Behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ce797",
   "metadata": {},
   "source": [
    "## Deviations from reach-match-safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6296388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No reach: Applied to an unselective program first\n",
    "df['unselective_first'] = df['offer_rate_1'] == 1\n",
    "\n",
    "# No match: Rejected by programs before matching to an unselective program\n",
    "df['no_match_program'] = df.apply(lambda row: row['offer_rate_match']==1 and row['matched_choice_num'] > 1 and row['matched']==True, axis=1)\n",
    "\n",
    "# No safety: Did not match to any programs\n",
    "df['not_matched'] = df['matched'] != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef4a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['interpretable_deviation'] = (df['unselective_first'] | df['no_match_program'] | df['not_matched'])\n",
    "print(df['unselective_first'].mean(),  df['no_match_program'].mean(), df['not_matched'].mean())\n",
    "print(df['interpretable_deviation'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f415e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_bar_chart(df, 'unselective_first', title='No Reach Program', save=False, savefolder=savefolder)\n",
    "create_bar_chart(df, 'no_match_program', title='No Match Program', save=False, savefolder=savefolder)\n",
    "create_bar_chart(df, 'not_matched', title='No Safety Program', save=False, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b5002",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_bar_chart(df, 'offer_rate_1', title='Offer Rate of Top-Ranked Program', save=False, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a60285",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['matched_to_1'] = df['matched_choice_num'] == 1\n",
    "create_bar_chart(df, 'matched_to_1', title='Matched to Top Choice', save=False, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f849ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['offer_rate_safety'] = df.apply(lambda row: np.nanmax([row[f'offer_rate_{i}'] for i in range(1, 13)]), axis=1)\n",
    "df['no_unselective'] = df['offer_rate_safety'] < 0.9\n",
    "create_bar_chart(df, 'no_unselective', title='No Unselective (Offer Rate > 0.9)', save=False, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8039ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['no_unselective']==True]['not_matched'].mean(), df[df['no_unselective']==False]['not_matched'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6ba19a",
   "metadata": {},
   "source": [
    "### Example portfolios from each deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a15a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_portfolio_outcome(df[df['unselective_first']].sample(1, random_state=8), title='No Reach Program', save=False, savefolder=savefolder)\n",
    "plot_portfolio_outcome(df[df['no_match_program']==1].sample(1, random_state=8), title='No Match Program', save=False, savefolder=savefolder)\n",
    "plot_portfolio_outcome(df[df['not_matched']==1].sample(1, random_state=9), title='No Safety Program', save=False, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51fc59b",
   "metadata": {},
   "source": [
    "### Inversions and Effective List Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52498651",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['undermatching_withinportfolio'] = df['offer_rate_match'] - df['offer_rate_best_cf_pareto_withinportfolio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd4683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stacked_bar_chart(df, ['undermatching', 'undermatching_withinportfolio'], labels=['Overall', 'In Portfolio'], title='Undermatching', save=False, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ddae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['inversion'] = df['undermatching_withinportfolio'] > 0\n",
    "df['inversion'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d78d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_bar_chart(df, 'inversion', title='Portfolio Contains Inversion', save=False, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4051989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ofchoices_effective(row):\n",
    "    for i in range(1, int(row['ofchoices'])):\n",
    "        if row[f'offer_rate_{i}'] == 1:\n",
    "            return i\n",
    "    else:\n",
    "        return row['ofchoices']\n",
    "    \n",
    "df['ofchoices_effective'] = df.apply(lambda row: get_ofchoices_effective(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cff912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_stacked_bar_chart(df, ['ofchoices', 'ofchoices_effective'], labels=['List Length', 'Effective List Length'], title='List Length', save=False, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a454d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_list'] = df['ofchoices']==12\n",
    "print(df['full_list'].mean())\n",
    "create_bar_chart(df, 'full_list', title='Full List', save=False, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f50752",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['ofchoices']==12]['not_matched'].mean())\n",
    "create_bar_chart(df[df['ofchoices']==12], 'not_matched', title='Not Matched Conditional on Full List', save=False, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b75445e",
   "metadata": {},
   "source": [
    "## Summary table of portfolio behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0d6c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_prevalences(df, metric):\n",
    "    prevalences = []\n",
    "    for FRL in [0,1]:\n",
    "        prevalences.append(round(df[df['poverty']==FRL][metric].mean(), 2))\n",
    "    for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "        prevalences.append(round(df[df['ethnicity']==ethnicity][metric].mean(), 2))\n",
    "    return prevalences\n",
    "\n",
    "metrics = ['unselective_first', 'offer_rate_1', 'no_match_program', 'not_matched', 'no_unselective', 'inversion', 'ofchoices', 'ofchoices_effective', 'no_unselective']\n",
    "\n",
    "rows = [[metric, *get_group_prevalences(df, metric)] for metric in metrics]\n",
    "\n",
    "df_behaviors = pd.DataFrame(rows, columns=['behavior', 'no FRL', 'FRL', 'Asian', 'Black', 'Hispanic', 'white'])\n",
    "df_behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b61ed81",
   "metadata": {},
   "source": [
    "# Model-based recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa8f941",
   "metadata": {},
   "source": [
    "## \"Utils\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b9fca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_programs = pd.read_csv('../clean_dfs/programs_with_apps_export.csv')\n",
    "df_sqr = pd.read_csv('../data/202223-hs-sqr-with-mean.csv')\n",
    "df_programs = df_programs.merge(df_sqr[['DBN','mean_SQR']], how='left', left_on='dbn', right_on='DBN').rename(columns={'mean_SQR_x':'mean_SQR'})\n",
    "\n",
    "# Load 2021 offer rate data to be used for recommendations\n",
    "cohort_directory = f'R:/CR4239/Cohort 2021-22/'\n",
    "df_2021 = pd.read_csv(cohort_directory+f'2021 HSAPS_Scrambled_for2939.csv', dtype={'student_id_scram':'string'}, low_memory=False)\n",
    "df_2021 = df_2021.drop_duplicates(subset = 'student_id_scram')\n",
    "    \n",
    "# filter for students who apply to at least one school, and GE only\n",
    "df_2021 = df_2021[df_2021['ofchoices'] >= 1]\n",
    "df_2021 = df_2021[df_2021['type'] == 'GE']\n",
    "df_2021.loc[~df_2021['matched_program'].str.contains(r'[A-Za-z0-9]{4}$', na=False), 'matched_program'] = np.nan\n",
    "df_2021.loc[~df_2021['finalprogramcode'].str.contains(r'[A-Za-z0-9]{4}$', na=False), 'finalprogramcode'] = np.nan\n",
    "\n",
    "df_programs_2021 = create_program_df(2021, include_ms_tests=False)\n",
    "df_programs_2021 = add_offer_rates(df_programs_2021, df_2021)\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "offer_rate_dict_2021 = dict(zip(df_programs_2021['programcode'], df_programs_2021['offer_rate']))\n",
    "offer_rate_dict_2021 = defaultdict(lambda: 1, offer_rate_dict_2021)\n",
    "\n",
    "num_matches_dict_2021 = defaultdict(int, Counter(df_2021['matched_program']))\n",
    "num_matches_dict_2022 = defaultdict(int, Counter(df['matched_program']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c4b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(probs):\n",
    "    increasing_probs = get_increasing_probs(probs)\n",
    "    score = 0\n",
    "    low = 0\n",
    "    increasing_probs.append(1)\n",
    "    for prob in increasing_probs:\n",
    "        score += prob * (prob - low)\n",
    "        low = prob\n",
    "    return score\n",
    "\n",
    "def get_increasing_probs(probs):\n",
    "    increasing_probs = []\n",
    "    increasing_args = []\n",
    "    for i, prob in enumerate(probs):\n",
    "        if i == 0:\n",
    "            increasing_probs.append(prob)\n",
    "            increasing_args.append(i)\n",
    "        else:\n",
    "            if prob > increasing_probs[-1]:\n",
    "                increasing_probs.append(prob)\n",
    "                increasing_args.append(i)\n",
    "    return increasing_probs\n",
    "\n",
    "# best way to change the program with a given rank\n",
    "def get_best_move(probs, candidate_args=False, only_reach=False):\n",
    "    best_arg = 0\n",
    "    best_move = 0\n",
    "    best_score = get_score(probs)\n",
    "    if not candidate_args:\n",
    "        candidate_args = range(len(probs))\n",
    "    \n",
    "    for arg in candidate_args:\n",
    "        increasing_probs = []\n",
    "        increasing_args = []\n",
    "        for i, prob in enumerate(probs):\n",
    "            if i == 0:\n",
    "                increasing_probs.append(prob)\n",
    "                increasing_args.append(i)\n",
    "            else:\n",
    "                if prob > increasing_probs[-1]:\n",
    "                    increasing_probs.append(prob)\n",
    "                    increasing_args.append(i)\n",
    "\n",
    "        low_neighbor = 0\n",
    "        i = arg - 1\n",
    "        while i >= 0:\n",
    "            if i in increasing_args:\n",
    "                low_neighbor = probs[i]\n",
    "                break\n",
    "            i -= 1\n",
    "\n",
    "\n",
    "        potential_high_neighbors = get_increasing_probs([low_neighbor, *probs[arg + 1:]])[1:]\n",
    "        potential_high_neighbors.append(1)\n",
    "        for high_neighbor in potential_high_neighbors:\n",
    "            probs_potential = probs.copy()\n",
    "            probs_potential[arg] = (low_neighbor + high_neighbor)/2\n",
    "            score = get_score(probs_potential)\n",
    "            if score < best_score:\n",
    "                best_move = (low_neighbor + high_neighbor)/2 - probs[arg]\n",
    "                best_score = score\n",
    "                best_arg = arg\n",
    "    \n",
    "    if only_reach:\n",
    "        if best_move > 0:\n",
    "            best_move = 0\n",
    "    return best_arg, best_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a55158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_portfolio_recommendation(row, title='recommended portfolio', save=False, savefolder= f'../plots_export_20250112/'):\n",
    "    offer_rates = row['offer_rates'].to_list()[0]\n",
    "    best_arg, best_move = row['best_move'].to_list()[0]\n",
    "    if np.abs(best_move) > 0.1:\n",
    "        best_move_shortened = -(np.abs(best_move) - 0.1) if best_move < 0 else best_move - 0.1\n",
    "    else:\n",
    "        best_move_shortened = 0\n",
    "    plt.figure(figsize=(6, 2))\n",
    "    plt.scatter(range(1, len(offer_rates)+1), offer_rates, color='black', label='old choices')\n",
    "    plt.scatter([best_arg + 1], [offer_rates[best_arg] + best_move], marker='s', color='green', label='recommended choice')\n",
    "    plt.arrow(best_arg + 1, offer_rates[best_arg], 0, best_move_shortened, head_width=0.2, head_length=0.05)\n",
    "    plt.xlim(0.5, 12.5)\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "    plt.xlabel('rank')\n",
    "    plt.ylabel('offer rate')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{savefolder}/{title}.pdf', dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c617cfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only close programs with counterfactuals\n",
    "df_zipzip = pd.read_csv('../zipzipdf.csv')\n",
    "\n",
    "zip_to_programs = defaultdict(lambda: [])\n",
    "\n",
    "for index, row in df_programs.iterrows():\n",
    "    zip_to_programs[row['zipcode']].append(row['programcode'])\n",
    "\n",
    "df_zipzip['programcode'] = df_zipzip['zip_dest'].apply(lambda x: zip_to_programs[x])\n",
    "df_zipzip = df_zipzip.explode('programcode', ignore_index=True)\n",
    "\n",
    "programs_counterfactual = df_programs[df_programs['counterfactual']]['programcode'].to_list()\n",
    "\n",
    "def filter_programs_by_radius(student_row, radius=30):\n",
    "    helper_df = df_zipzip[df_zipzip['zip_source']==student_row['zipcode']]\n",
    "    programs = helper_df.loc[helper_df['commute_time'] <= radius, 'programcode'].to_list()\n",
    "    return programs\n",
    "\n",
    "def get_close_programs_with_counterfactual(row):\n",
    "    if row['matched']:\n",
    "        result = df_zipzip.loc[(df_zipzip['zip_source']==row['zipcode']) & (df_zipzip['programcode']==row['matched_program']), 'commute_time']\n",
    "        if not result.empty:\n",
    "            radius = result.iloc[0]\n",
    "        else:\n",
    "            radius=30\n",
    "    else:\n",
    "        radius = 30\n",
    "    close_programs = filter_programs_by_radius(row, radius)\n",
    "    close_programs_with_counterfactual = list(set(close_programs) & set(programs_counterfactual))\n",
    "    return close_programs_with_counterfactual\n",
    "\n",
    "df['close_programs_with_counterfactual'] = df.apply(lambda row: get_close_programs_with_counterfactual(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a367572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# further filter to programs that had at least 25 matched students the previous year\n",
    "\n",
    "from collections import Counter\n",
    "num_matches_dict_2021 = defaultdict(int, Counter(df_2021['matched_program']))\n",
    "df['candidate_programs'] = df['close_programs_with_counterfactual'].apply(lambda x: [programcode for programcode in x if num_matches_dict_2021[programcode]>=25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f324c660",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd9ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for creating the best move to adjust individual portfolios\n",
    "\n",
    "df['offer_rates_2021'] = df.apply(lambda row: [offer_rate_dict_2021[row[f'programcode{i}']] for i in range(1, 13)], axis=1)\n",
    "\n",
    "df['best_move'] = df['offer_rates_2021'].apply(lambda x: get_best_move(x))\n",
    "df['best_move_first'] = df['offer_rates_2021'].apply(lambda x: get_best_move(x, candidate_args=[0], only_reach=True))\n",
    "\n",
    "df['best_move_arg'] = df['best_move'].apply(lambda x: x[0])\n",
    "df['best_move_offer_rate_change'] = df['best_move'].apply(lambda x: x[1])\n",
    "df['best_move_arg_first'] = df['best_move_first'].apply(lambda x: x[0])\n",
    "df['best_move_offer_rate_change_first'] = df['best_move_first'].apply(lambda x: x[1])\n",
    "\n",
    "def get_offer_rate(row, i):\n",
    "    return row['offer_rates_2021'][i]\n",
    "\n",
    "df['recommended_offer_rate'] = df.apply(lambda row: get_offer_rate(row, row['best_move_arg']) + row['best_move_offer_rate_change'], axis=1)\n",
    "df['recommended_offer_rate_first'] = df.apply(lambda row: get_offer_rate(row, row['best_move_arg_first']) + row['best_move_offer_rate_change_first'], axis=1)\n",
    "\n",
    "df['portfolio'] = df.apply(lambda row: [row[f'programcode{i}'] for i in range(1, 13)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d848314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_portfolio_recommendation(df.sample(1, random_state=8), title='Recommended portfolio 1', save=False, savefolder=savefolder)\n",
    "plot_portfolio_recommendation(df.sample(1, random_state=9), title='Recommended portfolio 2', save=False, savefolder=savefolder)\n",
    "plot_portfolio_recommendation(df.sample(1, random_state=10), title='Recommended portfolio 3', save=False, savefolder=savefolder)\n",
    "plot_portfolio_recommendation(df.sample(1, random_state=105), title='Recommended portfolio 4', save=False, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67bf3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a list of candidate programs, choose the program with the nearest offer rate to offer_rate, randomizing among the top r options\n",
    "def get_program_with_nearest_offer_rate(offer_rate, programs, r=1):\n",
    "    programs = [program for program in programs if program in offer_rate_dict_2021.keys()]\n",
    "    if len(programs) > 0:\n",
    "        program_offer_rates = np.array([offer_rate_dict_2021[program] for program in programs])\n",
    "        i = np.random.randint(np.min([r, len(programs)]))\n",
    "        arg = np.argsort(np.abs(offer_rate - program_offer_rates))[i]\n",
    "        return programs[arg]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# given a portfolio, compute the match\n",
    "def get_match(row, portfolio):\n",
    "    for program in portfolio:\n",
    "        if program == row['matched_program']:\n",
    "            return program\n",
    "        if program in programs_counterfactual and row[program]:\n",
    "            return program\n",
    "    return None\n",
    "\n",
    "# return a modified portfolio, changing the program in a given rank\n",
    "def make_change(portfolio, rank, program):\n",
    "    portfolio = portfolio.copy()\n",
    "    if len(portfolio) > 0 and pd.notnull(program):\n",
    "        portfolio[rank] = program\n",
    "    return portfolio\n",
    "\n",
    "offer_rate_dict = dict(zip(df_programs['programcode'], df_programs['offer_rate']))\n",
    "grad_rate_dict = dict(zip(df_programs['programcode'], df_programs['program_grad_rate']))\n",
    "college_rate_dict = dict(zip(df_programs['programcode'], df_programs['program_college_rate']))\n",
    "impact_dict = dict(zip(df_programs['programcode'], df_programs['impact']))\n",
    "performance_dict = dict(zip(df_programs['programcode'], df_programs['performance']))\n",
    "aggregated_quality_dict = dict(zip(df_programs['programcode'], df_programs['aggregated_quality']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c29dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recommended_program_one'] = df.apply(lambda row: get_program_with_nearest_offer_rate(row['recommended_offer_rate'], row['candidate_programs'], r=1), axis=1)\n",
    "df['recommended_program_first'] = df.apply(lambda row: get_program_with_nearest_offer_rate(row['recommended_offer_rate_first'], row['candidate_programs'], r=1), axis=1)\n",
    "df['portfolio_one'] = df.apply(lambda row: make_change(row['portfolio'], row['best_move'][0], row['recommended_program_one']), axis=1)\n",
    "df['portfolio_first'] = df.apply(lambda row: make_change(row['portfolio'], row['best_move_first'][0], row['recommended_program_first']), axis=1)\n",
    "df['portfolio_optimal'] = df['close_programs_with_counterfactual'].apply(lambda programs: [get_program_with_nearest_offer_rate(i/13, programs, r=1) for i in range(1, 13)])\n",
    "df['portfolio_optimal_with_safety'] = df['close_programs_with_counterfactual'].apply(lambda programs: [get_program_with_nearest_offer_rate(i/13, programs, r=1) for i in range(1, 14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd35ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_portfolio_result_cols(df, portfolio_col):\n",
    "    mp_grad_rate_mean = df['program_grad_rate_mp'].mean()\n",
    "    mp_college_rate_mean = df['program_college_rate_mp'].mean()\n",
    "    mp_impact_mean = df['impact_mp'].mean()\n",
    "    mp_performance_mean = df['performance_mp'].mean()\n",
    "    mp_aggregated_quality_mean = df['aggregated_quality_mp'].mean()\n",
    "\n",
    "    df[f'{portfolio_col}_match'] = df.apply(lambda row: get_match(row, row[f'{portfolio_col}']), axis=1)\n",
    "    \n",
    "    df[f'{portfolio_col}_match_offer_rate_diff'] = df[f'{portfolio_col}_match'].apply(lambda x: offer_rate_dict[x] if pd.notnull(x) else 1) - df['offer_rate_match']\n",
    "    df[f'{portfolio_col}_match_grad_rate_diff'] = df[f'{portfolio_col}_match'].apply(lambda x: grad_rate_dict[x] if pd.notnull(x) else mp_grad_rate_mean) - df['program_grad_rate_match']\n",
    "    df[f'{portfolio_col}_match_college_rate_diff'] = df[f'{portfolio_col}_match'].apply(lambda x: college_rate_dict[x] if pd.notnull(x) else mp_college_rate_mean) - df['program_college_rate_match']\n",
    "    df[f'{portfolio_col}_match_impact_diff'] = df[f'{portfolio_col}_match'].apply(lambda x: impact_dict[x] if pd.notnull(x) else mp_impact_mean) - df['impact_match']\n",
    "    df[f'{portfolio_col}_match_performance_diff'] = df[f'{portfolio_col}_match'].apply(lambda x: performance_dict[x] if pd.notnull(x) else mp_performance_mean) - df['performance_match']\n",
    "    df[f'{portfolio_col}_match_aggregated_quality_diff'] = df[f'{portfolio_col}_match'].apply(lambda x: aggregated_quality_dict[x] if pd.notnull(x) else mp_aggregated_quality_mean) - df['aggregated_quality_match']\n",
    "\n",
    "    return\n",
    "\n",
    "pretty_names = {'portfolio_one': 'Single', 'portfolio_first': 'Top', 'portfolio_optimal': 'Full'}\n",
    "def plot_portfolio_results(df, portfolio_col):\n",
    "    for metric, title in [('offer_rate', 'Offer Rate'), ('grad_rate', 'Grad. Rate'), ('college_rate', 'College Rate'), ('impact', 'Impact'), ('performance', 'Performance'), ('aggregated_quality', 'Aggr. Quality')]:\n",
    "        create_bar_chart(df, f'{portfolio_col}_match_{metric}_diff', title=f'Change in {title} ({pretty_names[portfolio_col]})', save=True, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da5af1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for portfolio_col in ['portfolio_one', 'portfolio_first', 'portfolio_optimal']:\n",
    "    add_portfolio_result_cols(df, portfolio_col)\n",
    "    print(df[f'{portfolio_col}_match_offer_rate_diff'].mean()/df['undermatching'].mean())\n",
    "    plot_portfolio_results(df, portfolio_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04d84c7",
   "metadata": {},
   "source": [
    "## Heatmap of recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e305d6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "axes = axes.flatten()\n",
    "for i, ax in enumerate(axes):\n",
    "    sns.histplot(x=df[df['ethnicity']==groups[i]]['best_move_arg'], y=df[df['ethnicity']==groups[i]]['best_move_offer_rate_change'], bins=[np.linspace(-0.5,11.5,13), np.linspace(-1,1,21)], ax=ax, cbar=True, cmap='Blues', vmin=0)\n",
    "    ax.plot([-0.5,11.5], [0,0], color='black', linestyle=\"--\", linewidth=1)\n",
    "    ax.set_xlabel('List Position')\n",
    "    ax.set_ylabel('Change in Offer Rate')\n",
    "    ax.set_xlim(-0.5,11.5)\n",
    "    ax.set_ylim(-1.1,1.1)\n",
    "    ax.set_xticks(range(12), range(1, 13))\n",
    "    ax.set_title(f'Recommendations for {group_names_pretty[groups[i]]} students')\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig(f'{savefolder}/heatmap.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e14d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 13), [(df['best_move_arg']==i).sum()/len(df) for i in range(12)])\n",
    "print((df['best_move_arg']==0).sum()/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8429165b-2894-43eb-94f3-cb8962d29a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Proportion recommended to reach')\n",
    "print('overall',  (df['best_move_offer_rate_change'] < 0).mean())\n",
    "for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "    print(ethnicity, (df[df['ethnicity']==ethnicity]['best_move_offer_rate_change'] < 0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c816498-573c-4404-ac5b-6f260f0ef2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average position')\n",
    "print('overall',  (df['best_move_arg']).mean())\n",
    "for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "    print(ethnicity, (df[df['ethnicity']==ethnicity]['best_move_arg']).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f047cc",
   "metadata": {},
   "source": [
    "# Supplemental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60866f31",
   "metadata": {},
   "source": [
    "Offer rate by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61942c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, title in [('offer_rate', 'Offer Rate'), ('program_grad_rate', 'Graduation Rate'), ('program_college_rate', 'College Attendance Rate'), ('impact', 'Impact'), ('performance', 'Performance'), ('aggregated_quality', 'Aggregated Quality')]:\n",
    "\n",
    "    for i in range(1, 13):\n",
    "        offer_rates_by_position = []\n",
    "        df_temp = df[df['ofchoices']==i]\n",
    "        for j in range(1, i+1):\n",
    "            offer_rates_by_position.append(df_temp[f'{metric}_{j}'].mean())    \n",
    "        plt.plot(range(1, i+1), offer_rates_by_position, label=str(i), marker='o')\n",
    "\n",
    "    plt.xlabel('Rank in List',  fontsize=12)\n",
    "    plt.ylabel(f'{title}',  fontsize=12)\n",
    "    plt.legend(title='# of choices')\n",
    "    sns.despine()\n",
    "    plt.savefig(f'{savefolder}/{metric}_by_position_by_ofchoices.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4e694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_12 = df[df['ofchoices']==12]\n",
    "\n",
    "for metric, title in [('offer_rate', 'Offer Rate'), ('program_grad_rate', 'Graduation Rate'), ('program_college_rate', 'College Attendance Rate'), ('impact', 'Impact'), ('performance', 'Performance'), ('aggregated_quality', 'Aggregated Quality')]:\n",
    "    for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "\n",
    "        offer_rates_by_position = []\n",
    "        for i in range(1, 13):\n",
    "            offer_rates_by_position.append(df[df['ethnicity']==ethnicity][f'{metric}_{i}'].mean())\n",
    "\n",
    "        plt.plot(range(1, 13), offer_rates_by_position, label=group_names_pretty[ethnicity], marker='o')\n",
    "\n",
    "    plt.xlabel('Rank in List', fontsize=12)\n",
    "    plt.ylabel(f'{title}', fontsize=12)\n",
    "    plt.legend()\n",
    "    sns.despine()\n",
    "    plt.savefig(f'{savefolder}/{metric}_by_position_by_ethnicity.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05f4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12 = df[df['ofchoices']==12]\n",
    "\n",
    "FRL_labels = ['No FRL', 'FRL']\n",
    "for metric, title in [('offer_rate', 'Offer Rate'), ('program_grad_rate', 'Graduation Rate'), ('program_college_rate', 'College Attendance Rate'), ('impact', 'Impact'), ('performance', 'Performance'), ('aggregated_quality', 'Aggregated Quality')]:\n",
    "    for FRL in [0,1]:\n",
    "\n",
    "        offer_rates_by_position = []\n",
    "        for i in range(1, 13):\n",
    "            offer_rates_by_position.append(df[df['poverty']==FRL][f'{metric}_{i}'].mean())\n",
    "\n",
    "        plt.plot(range(1, 13), offer_rates_by_position, label=FRL_labels[FRL], marker='o')\n",
    "\n",
    "    plt.xlabel('Rank in List', fontsize=12)\n",
    "    plt.ylabel(f'{title}', fontsize=12)\n",
    "    plt.legend()\n",
    "    sns.despine()\n",
    "    plt.savefig(f'{savefolder}/{metric}_by_position_by_FRL.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f3e1a8",
   "metadata": {},
   "source": [
    "# Simulate DA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8764bfd",
   "metadata": {},
   "source": [
    "## Compute program / seat group capacities\n",
    "\n",
    "For programs that have excess capacity, we assume capacity = max(# students who match, stated capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdef1124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_counterfactual_with_scores import get_seatgroup_scores\n",
    "import deferred_acceptance as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a63bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_scores, seat_group_fractions_dict, programs_counterfactual = get_seatgroup_scores(df, df_programs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee9f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_matches_dict = defaultdict(int, Counter(df['matched_program']))\n",
    "df_programs['num_matches'] = df_programs['programcode'].apply(lambda x: num_matches_dict[x])\n",
    "\n",
    "programs = df_programs['programcode'].to_list()\n",
    "num_seat_groups_dict = {}\n",
    "for program in programs:\n",
    "    if program in programs_counterfactual:\n",
    "        num_seat_groups_dict[program] = len(seat_group_fractions_dict[program])\n",
    "    else:\n",
    "        num_seat_groups_dict[program] = 1\n",
    "\n",
    "seatgroups = [[f'{programcode}-{i}' for i in range(num_seat_groups_dict[programcode])] for programcode in programs]\n",
    "seatgroups = [seatgroup for program_seatgroups in seatgroups for seatgroup in program_seatgroups]\n",
    "seatgroup_arg_dict = {}\n",
    "for i, seatgroup in enumerate(seatgroups):\n",
    "    seatgroup_arg_dict[seatgroup] = i\n",
    "\n",
    "seatgroup_to_program_dict = {}\n",
    "for seatgroup in seatgroups:\n",
    "    seatgroup_to_program_dict[seatgroup] = seatgroup[:4]\n",
    "\n",
    "matched_students_dict = {programcode: [] for programcode in programs}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    programcode = row['matched_program']\n",
    "    if pd.notnull(programcode):\n",
    "        matched_students_dict[programcode].append(index)\n",
    "\n",
    "seatgroup_prefs = []\n",
    "for seatgroup in seatgroups:\n",
    "    if seatgroup_to_program_dict[seatgroup] in programs_counterfactual:\n",
    "        seatgroup_prefs.append(np.argsort(-np.array(df_scores[seatgroup].to_list())))\n",
    "    else:\n",
    "        seatgroup_prefs.append(matched_students_dict[seatgroup_to_program_dict[seatgroup]])\n",
    "\n",
    "seatgroup_caps_dict = {}\n",
    "for programcode in programs:\n",
    "    if programcode in programs_counterfactual:\n",
    "        if offer_rate_dict[programcode] == 1:\n",
    "            seat_count = 0\n",
    "            for i, frac in enumerate(seat_group_fractions_dict[programcode]):\n",
    "                if i == len(seat_group_fractions_dict[programcode]) - 1:\n",
    "                    seatgroup_caps_dict[f'{programcode}-{i}'] = num_matches_dict[programcode] - seat_count\n",
    "                else:\n",
    "                    seatgroup_caps_dict[f'{programcode}-{i}']  = int(num_matches_dict[programcode] * frac)\n",
    "                    seat_count += int(num_matches_dict[programcode] * frac)\n",
    "        else:\n",
    "            seat_count = 0\n",
    "            for i, frac in enumerate(seat_group_fractions_dict[programcode]):\n",
    "                if i == len(seat_group_fractions_dict[programcode]) - 1:\n",
    "                    seatgroup_caps_dict[f'{programcode}-{i}'] = num_matches_dict[programcode] - seat_count\n",
    "                else:\n",
    "                    seatgroup_caps_dict[f'{programcode}-{i}']  = int(num_matches_dict[programcode] * frac)\n",
    "                    seat_count += int(num_matches_dict[programcode] * frac)\n",
    "    else:\n",
    "        seatgroup_caps_dict[f'{programcode}-0'] = num_matches_dict[programcode]\n",
    "        \n",
    "seatgroup_caps = [seatgroup_caps_dict[seatgroup] for seatgroup in seatgroups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a62e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def programs_to_seatgroup_args(programs):\n",
    "    seatgroups = []\n",
    "    for programcode in programs:\n",
    "        if pd.notnull(programcode):\n",
    "            for i in range(num_seat_groups_dict[programcode]):\n",
    "                seatgroups.append(f'{programcode}-{i}')\n",
    "    return [seatgroup_arg_dict[seatgroup] for seatgroup in seatgroups]\n",
    "\n",
    "def add_predicted_equilibrium_match(df, student_prefs, seatgroup_prefs, seatgroup_caps, outcome_col):\n",
    "    student_matches, seatgroup_matches = da.get_match(student_prefs, seatgroup_prefs, seatgroup_caps)\n",
    "    df[outcome_col] = [seatgroup_to_program_dict[seatgroups[i]] if i>=0 else np.nan for i in student_matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccdd8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recommended_program_one'] = df.apply(lambda row: get_program_with_nearest_offer_rate(row['recommended_offer_rate'], row['candidate_programs'], r=5), axis=1)\n",
    "df['recommended_program_first'] = df.apply(lambda row: get_program_with_nearest_offer_rate(row['recommended_offer_rate_first'], row['candidate_programs'], r=5), axis=1)\n",
    "df['portfolio_one'] = df.apply(lambda row: make_change(row['portfolio'], row['best_move'][0], row['recommended_program_one']), axis=1)\n",
    "df['portfolio_first'] = df.apply(lambda row: make_change(row['portfolio'], row['best_move_first'][0], row['recommended_program_first']), axis=1)\n",
    "df['portfolio_optimal'] = df['close_programs_with_counterfactual'].apply(lambda programs: [get_program_with_nearest_offer_rate(i/13, programs, r=5) for i in range(1, 13)])\n",
    "df['portfolio_optimal_with_safety'] = df['close_programs_with_counterfactual'].apply(lambda programs: [get_program_with_nearest_offer_rate(i/13, programs, r=5) for i in range(1, 14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e50b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_prefs_original = [programs_to_seatgroup_args(portfolio) for portfolio in df['portfolio'].to_list()]\n",
    "student_prefs_one = [programs_to_seatgroup_args(portfolio) for portfolio in df['portfolio_one'].to_list()]\n",
    "student_prefs_first= [programs_to_seatgroup_args(portfolio) for portfolio in df['portfolio_first'].to_list()]\n",
    "student_prefs_optimal= [programs_to_seatgroup_args(portfolio) for portfolio in df['portfolio_optimal'].to_list()]\n",
    "student_prefs_optimal_with_safety= [programs_to_seatgroup_args(portfolio) for portfolio in df['portfolio_optimal_with_safety'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45961adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_predicted_equilibrium_match(df, student_prefs_original, seatgroup_prefs, seatgroup_caps, 'equilibrium_match_original')\n",
    "add_predicted_equilibrium_match(df, student_prefs_one, seatgroup_prefs, seatgroup_caps, 'equilibrium_match_one')\n",
    "add_predicted_equilibrium_match(df, student_prefs_first, seatgroup_prefs, seatgroup_caps, 'equilibrium_match_first')\n",
    "add_predicted_equilibrium_match(df, student_prefs_optimal, seatgroup_prefs, seatgroup_caps, 'equilibrium_match_optimal')\n",
    "add_predicted_equilibrium_match(df, student_prefs_optimal_with_safety, seatgroup_prefs, seatgroup_caps, 'equilibrium_match_optimal_with_safety')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee7416",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (df['equilibrium_match_original'].fillna('no match') == df['matched_program'].fillna('no match')).mean()\n",
    "print(f'Accuracy of simulation on original preferences: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875dc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df['matched_program'].isna()).mean())\n",
    "print((df['equilibrium_match_one'].isna()).mean())\n",
    "print((df['equilibrium_match_first'].isna()).mean())\n",
    "print((df['equilibrium_match_optimal'].isna()).mean())\n",
    "print((df['equilibrium_match_optimal_with_safety'].isna()).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc3a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_match_column_post_manual_placement(df, match_col, match_col_post):\n",
    "\n",
    "    num_matches_predicted_dict = defaultdict(int, Counter(df[match_col]))\n",
    "\n",
    "    leftover_seats = {}\n",
    "    for x in offer_rate_dict.keys():\n",
    "        leftover_seats[x] = num_matches_dict[x] - num_matches_predicted_dict[x] \n",
    "\n",
    "    offer_rate_programs = list(offer_rate_dict.keys())\n",
    "    offer_rates = [offer_rate_dict[x] for x in offer_rate_dict.keys()]\n",
    "    offer_rate_args_sorted = np.argsort(offer_rates)\n",
    "\n",
    "    empty_seats = 0\n",
    "    for i in offer_rate_args_sorted:\n",
    "        x = offer_rate_programs[i]\n",
    "        empty_seats += leftover_seats[x]\n",
    "\n",
    "    df[match_col_post] = df[match_col].apply(lambda x: x)\n",
    "\n",
    "    j = 0\n",
    "    while leftover_seats[offer_rate_programs[offer_rate_args_sorted[j]]] < 1:\n",
    "        j += 1\n",
    "\n",
    "    shuffled_indices = np.random.permutation(df.index)\n",
    "\n",
    "    for idx in shuffled_indices:\n",
    "        if pd.isna(df.at[idx, match_col]):\n",
    "            # find next lowest offer rate program with seats open\n",
    "            try:\n",
    "                while leftover_seats[offer_rate_programs[offer_rate_args_sorted[j]]] < 1:\n",
    "                    j += 1\n",
    "            except:\n",
    "                break\n",
    "\n",
    "            program = offer_rate_programs[offer_rate_args_sorted[j]]\n",
    "            df.at[idx, match_col_post] = program\n",
    "            leftover_seats[program] -= 1\n",
    "            \n",
    "def add_match_col_results(df, match_col):\n",
    "    mp_grad_rate_mean = df['program_grad_rate_mp'].mean()\n",
    "    mp_college_rate_mean = df['program_college_rate_mp'].mean()\n",
    "    mp_impact_mean = df['impact_mp'].mean()\n",
    "    mp_performance_mean = df['performance_mp'].mean()\n",
    "    mp_aggregated_quality_mean = df['aggregated_quality_mp'].mean()\n",
    "\n",
    "    df[f'{match_col}_offer_rate_diff'] = df[f'{match_col}'].apply(lambda x: offer_rate_dict[x] if pd.notnull(x) else 1) - df['offer_rate_match']\n",
    "    df[f'{match_col}_grad_rate_diff'] = df[f'{match_col}'].apply(lambda x: grad_rate_dict[x] if pd.notnull(x) else mp_grad_rate_mean) - df['program_grad_rate_match']\n",
    "    df[f'{match_col}_college_rate_diff'] = df[f'{match_col}'].apply(lambda x: college_rate_dict[x] if pd.notnull(x) else mp_college_rate_mean) - df['program_college_rate_match']\n",
    "    df[f'{match_col}_impact_diff'] = df[f'{match_col}'].apply(lambda x: impact_dict[x] if pd.notnull(x) else mp_impact_mean) - df['impact_match']\n",
    "    df[f'{match_col}_performance_diff'] = df[f'{match_col}'].apply(lambda x: performance_dict[x] if pd.notnull(x) else mp_performance_mean) - df['performance_match']\n",
    "    df[f'{match_col}_aggregated_quality_diff'] = df[f'{match_col}'].apply(lambda x: aggregated_quality_dict[x] if pd.notnull(x) else mp_aggregated_quality_mean) - df['aggregated_quality_match']\n",
    "\n",
    "    return\n",
    "\n",
    "pretty_names = {'equilibrium_match_one_post': 'Single', 'equilibrium_match_first_post': 'Top', 'equilibrium_match_optimal_post': 'Full'}\n",
    "def plot_equilibrium_match_results(df, match_col):\n",
    "    for metric, title in [('offer_rate', 'Offer Rate'), ('grad_rate', 'Grad. Rate'), ('college_rate', 'College Rate'), ('impact', 'Impact'), ('performance', 'Performance'), ('aggregated_quality', 'Aggr. Quality')]:\n",
    "        create_bar_chart(df, f'{match_col}_{metric}_diff', title=f'Eq. Change in {title} ({pretty_names[match_col]})', save=True, savefolder=savefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b1320",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match_col in ['equilibrium_match_one', 'equilibrium_match_first', 'equilibrium_match_optimal']:\n",
    "    add_match_column_post_manual_placement(df, match_col, match_col + '_post')\n",
    "    add_match_col_results(df, match_col + '_post')\n",
    "    plot_equilibrium_match_results(df, match_col + '_post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b17f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity = df[df['ethnicity']=='white']['offer_rate_match'].mean() - df[df['ethnicity']=='black']['offer_rate_match'].mean()\n",
    "for match_col in ['equilibrium_match_one', 'equilibrium_match_first', 'equilibrium_match_optimal']:\n",
    "    disparity_reduction = df[df['ethnicity']=='white'][f'{match_col}_post_offer_rate_diff'].mean() - df[df['ethnicity']=='black'][f'{match_col}_post_offer_rate_diff'].mean()\n",
    "    print(disparity_reduction, disparity_reduction/disparity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b282f596-811e-46c1-8252-5d4db5a2d5d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Change in disparity among most competitive students (best counterfactual offer rate)')\n",
    "disparity = df[(df['offer_rate_cf_bin']==0) & (df['ethnicity']=='white')]['offer_rate_match'].mean() - df[(df['offer_rate_cf_bin']==0) & (df['ethnicity']=='black')]['offer_rate_match'].mean()\n",
    "disparity_reduction = df[(df['offer_rate_cf_bin']==0) & (df['ethnicity']=='white')]['equilibrium_match_one_post_offer_rate_diff'].mean() - df[(df['offer_rate_cf_bin']==0) & (df['ethnicity']=='black')]['equilibrium_match_one_post_offer_rate_diff'].mean()\n",
    "print(disparity_reduction, disparity_reduction/disparity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d538bcae",
   "metadata": {},
   "source": [
    "# Comparing to offer rates in past years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f7653b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "offer_rates_2021, offer_rates_2022 = [], []\n",
    "for programcode in offer_rate_dict.keys():\n",
    "    if programcode in offer_rate_dict_2021.keys():\n",
    "        if num_matches_dict_2021[programcode] > 25:\n",
    "            offer_rates_2021.append(offer_rate_dict_2021[programcode])\n",
    "            offer_rates_2022.append(offer_rate_dict[programcode])\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(offer_rates_2021, offer_rates_2022, alpha=0.3)\n",
    "plt.xlabel('Offer Rate 2021', fontsize=12)\n",
    "plt.ylabel('Offer Rate 2022', fontsize=12)\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig(f'{savefolder}/offer_rate_2021_2022.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dbd492",
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_rates_2021 = np.array(offer_rates_2021)\n",
    "offer_rates_2022 = np.array(offer_rates_2022)\n",
    "print('percent that stay unselective', (offer_rates_2022[offer_rates_2021 == 1]==1).sum()/(offer_rates_2021 == 1).sum())\n",
    "print('offer rate of previously unselective', (offer_rates_2022[offer_rates_2021 == 1]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43b2186-8fd9-45e9-a794-72b5ef3f5767",
   "metadata": {},
   "source": [
    "# Results restricting to students who eventually enroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f914e-8279-474b-a78a-dd67d0954231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_enrollment = pd.read_csv('R:/CR4239/Cohort 2022-23/2023-24_HsCourseAndGrades_Scrambled_for2939.csv')\n",
    "id_to_enrolled_dbn = dict(zip(df_enrollment['student_id_scram'], df_enrollment['dbn']))\n",
    "df['enrolled_dbn'] = df['student_id_scram'].apply(lambda x: id_to_enrolled_dbn.get(x))\n",
    "print('percent enrolled')\n",
    "for ethnicity in ['asian', 'black', 'white', 'hispanic']:\n",
    "    print(ethnicity, df[df['ethnicity']==ethnicity]['enrolled_dbn'].isna().mean())\n",
    "\n",
    "print('percent enrolled among those who did not match')\n",
    "df['not_matched'] = df['matched'] != 1\n",
    "for ethnicity in ['asian', 'black', 'white', 'hispanic']:\n",
    "    print(ethnicity, df[(df['not_matched']) & (df['ethnicity']==ethnicity)]['enrolled_dbn'].isna().mean())\n",
    "\n",
    "print('percent did not match among those who did enroll')\n",
    "for ethnicity in ['asian', 'black', 'white', 'hispanic']:\n",
    "    print(ethnicity, df[(df['enrolled_dbn'].notna()) & (df['ethnicity']==ethnicity)]['not_matched'].mean())\n",
    "\n",
    "print('percent did not match among those who did not enroll')\n",
    "for ethnicity in ['asian', 'black', 'white', 'hispanic']:\n",
    "    print(ethnicity, df[(df['enrolled_dbn'].isna()) & (df['ethnicity']==ethnicity)]['not_matched'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c66cccb-f17e-4d67-ae01-2e81c14af760",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Proportion recommended to reach')\n",
    "for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "    print(ethnicity, (df[(df['enrolled_dbn'].notna()) & (df['ethnicity']==ethnicity)]['best_move_offer_rate_change'] < 0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89894694-f01c-4efe-bfc5-78b972708adc",
   "metadata": {},
   "source": [
    "# Undermatching results when accounting for other preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4170eed-d224-494c-85a6-822c3d81a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['undermatching_homophily'] = df['offer_rate_match'] - df['offer_rate_best_cf_pareto_homophily']\n",
    "df['undermatching_safety'] = df['offer_rate_match'] - df['offer_rate_best_cf_pareto_safe']\n",
    "df['undermatching_within_33'] = df['offer_rate_match'] - df['offer_rate_best_cf_pareto_within_33']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b20b6ee-6a33-455d-b97a-06553ee5ffc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for suffix in ['homophily', 'safe', 'within_33']:\n",
    "    for metric in ['offer_rate', 'program_college_rate', 'program_grad_rate', 'impact', 'performance', 'aggregated_quality']:\n",
    "        df[f'undermatching_{metric}_{suffix}'] = df[f'{metric}_best_cf_pareto_{suffix}'] - df[f'{metric}_match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260b5de-9af4-4927-8b7c-e01881964f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for suffix in ['homophily', 'safe', 'within_33']:\n",
    "    table = ''\n",
    "    for metric in ['offer_rate', 'program_college_rate', 'program_grad_rate', 'impact', 'performance']:\n",
    "        table_row = ''\n",
    "        table_row += str(round(df[f'{metric}_match'].mean(), 2)) + ' & '\n",
    "        for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "            table_row += str(round(df[df['ethnicity']==ethnicity][f'{metric}_match'].mean(), 2)) + ' & '\n",
    "        table_row += str(round(df[f'{metric}_best_cf_pareto_{suffix}'].mean(), 2)) + ' & '\n",
    "        for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "            table_row += str(round(df[df['ethnicity']==ethnicity][f'{metric}_best_cf_pareto_{suffix}'].mean(), 2)) + ' & '\n",
    "        table_row += str(round(df[f'undermatching_{metric}_{suffix}'].mean(), 2)) + ' & '\n",
    "        for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "            table_row += str(round(df[df['ethnicity']==ethnicity][f'undermatching_{metric}_{suffix}'].mean(), 2)) + ' & '\n",
    "        table += table_row + '\\n'\n",
    "    \n",
    "        table_row = ''\n",
    "        table_row += str(round(df[df['poverty']==True][f'{metric}_match'].mean(), 2)) + ' & '\n",
    "        for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "            table_row += str(round(df[(df['ethnicity']==ethnicity) & (df['poverty']==True)][f'{metric}_match'].mean(), 2)) + ' & '\n",
    "        table_row += str(round(df[df['poverty']==True][f'{metric}_best_cf_pareto_{suffix}'].mean(), 2)) + ' & '\n",
    "        for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "            table_row += str(round(df[(df['ethnicity']==ethnicity) & (df['poverty']==True)][f'{metric}_best_cf_pareto_{suffix}'].mean(), 2)) + ' & '\n",
    "        table_row += str(round(df[df['poverty']==True][f'undermatching_{metric}_{suffix}'].mean(), 2)) + ' & '\n",
    "        for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "            table_row += str(round(df[(df['ethnicity']==ethnicity) & (df['poverty']==True)][f'undermatching_{metric}_{suffix}'].mean(), 2)) + ' & '\n",
    "        table += table_row + '\\n'\n",
    "    \n",
    "        table_row = ''\n",
    "        table_row += str(round(df[df['poverty']==False][f'{metric}_match'].mean(), 2)) + ' & '\n",
    "        for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "            table_row += str(round(df[(df['ethnicity']==ethnicity) & (df['poverty']==False)][f'{metric}_match'].mean(), 2)) + ' & '\n",
    "        table_row += str(round(df[df['poverty']==False][f'{metric}_best_cf_pareto_{suffix}'].mean(), 2)) + ' & '\n",
    "        for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "            table_row += str(round(df[(df['ethnicity']==ethnicity) & (df['poverty']==False)][f'{metric}_best_cf_pareto_{suffix}'].mean(), 2)) + ' & '\n",
    "        table_row += str(round(df[df['poverty']==False][f'undermatching_{metric}_{suffix}'].mean(), 2)) + ' & '\n",
    "        for ethnicity in ['asian', 'black', 'hispanic', 'white']:\n",
    "            table_row += str(round(df[(df['ethnicity']==ethnicity) & (df['poverty']==False)][f'undermatching_{metric}_{suffix}'].mean(), 2)) + ' & '\n",
    "        table += table_row + '\\n'\n",
    "    \n",
    "    with open(f'{savefolder}/undermatching_table_{suffix}.txt', 'w') as f:\n",
    "        f.write(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
